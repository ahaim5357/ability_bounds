{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Experiments\n",
    "\n",
    "In this notebook, we generate synthetic data sets with a ground truth item response theory model and test how often the bounds returned by various confidence bound methods actually include the 'true' ability parameter and how precisely the bound estimates the difference between true parameter and estimated parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data generation function\n",
    "def sample_data(m, n):\n",
    "    theta = np.random.randn(m)\n",
    "    b     = np.random.randn(n)\n",
    "    P     = 1. / (1. + np.exp(-(np.expand_dims(theta, 1) - np.expand_dims(b, 0))))\n",
    "    X     = np.random.rand(m, n)\n",
    "    X[X >= 1. - P] = 1.\n",
    "    X[X <  1. - P] = 0.\n",
    "    return theta, b, P, X\n",
    "# set up a function to evaluate coverage\n",
    "def eval_coverage(theta, theta_min, theta_max):\n",
    "    return np.mean(np.logical_and(theta >= theta_min, theta <= theta_max))\n",
    "# set up a function to compare the bound size with the size needed to cover the true theta\n",
    "def eval_logbias(theta, theta_est, theta_min, theta_max):\n",
    "    ratios  = np.zeros_like(theta)\n",
    "    small = theta < theta_est\n",
    "    lo    = theta_est[small] - theta_min[small]\n",
    "    ratios[small] = lo / (theta_est[small] - theta[small])\n",
    "    large = theta >= theta_est\n",
    "    hi    = theta_max[large] - theta_est[large]\n",
    "    ratios[large] = hi / (theta[large] - theta_est[large])\n",
    "    return np.mean(np.log(ratios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up experimental hyper-parameters\n",
    "experimental_conditions = [\n",
    "    (30, 10),\n",
    "    (30, 20),\n",
    "    (50, 10),\n",
    "    (50, 20),\n",
    "    (100, 10),\n",
    "    (100, 20),\n",
    "    (500, 10),\n",
    "    (500, 20)\n",
    "]\n",
    "R     = 10\n",
    "\n",
    "regul = 1.\n",
    "alpha = .95\n",
    "from scipy.stats import chi2\n",
    "absolute_bound = .5 * chi2.ppf(alpha, df = 1)\n",
    "mu    = .01\n",
    "\n",
    "method_labels = ['wald', 'likelihood-profile', 'barrier', 'AO(1)', 'AO(2)', 'AO(3)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- condition 1; m = 30, n = 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method              \tcoverage\tlogbias\t\truntime\n",
      "wald                \t0.983 +- 0.022\t1.721 +- 0.177\t0.005 +- 0.000\n",
      "likelihood-profile  \t0.943 +- 0.054\t1.280 +- 0.179\t0.316 +- 0.008\n",
      "barrier             \t0.910 +- 0.056\t1.113 +- 0.179\t0.045 +- 0.001\n",
      "AO(1)               \t0.943 +- 0.054\t1.260 +- 0.179\t0.020 +- 0.000\n",
      "AO(2)               \t0.943 +- 0.054\t1.280 +- 0.179\t0.108 +- 0.002\n",
      "AO(3)               \t0.943 +- 0.054\t1.280 +- 0.179\t0.171 +- 0.002\n",
      "--- condition 2; m = 30, n = 20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]<ipython-input-1-178cdb071133>:22: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.mean(np.log(ratios))\n",
      "100%|██████████| 10/10 [00:07<00:00,  1.41it/s]\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:230: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method              \tcoverage\tlogbias\t\truntime\n",
      "wald                \t1.000 +- 0.000\t1.988 +- 0.186\t0.006 +- 0.001\n",
      "likelihood-profile  \t0.943 +- 0.021\t1.339 +- 0.201\t0.333 +- 0.005\n",
      "barrier             \t0.083 +- 0.050\t-inf +- nan\t0.035 +- 0.001\n",
      "AO(1)               \t0.940 +- 0.025\t1.305 +- 0.202\t0.021 +- 0.001\n",
      "AO(2)               \t0.943 +- 0.021\t1.339 +- 0.201\t0.118 +- 0.002\n",
      "AO(3)               \t0.943 +- 0.021\t1.339 +- 0.201\t0.193 +- 0.002\n",
      "--- condition 3; m = 50, n = 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:11<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method              \tcoverage\tlogbias\t\truntime\n",
      "wald                \t0.998 +- 0.006\t1.787 +- 0.097\t0.007 +- 0.001\n",
      "likelihood-profile  \t0.926 +- 0.041\t1.308 +- 0.090\t0.572 +- 0.017\n",
      "barrier             \t0.884 +- 0.047\t1.158 +- 0.099\t0.075 +- 0.003\n",
      "AO(1)               \t0.920 +- 0.041\t1.293 +- 0.089\t0.031 +- 0.000\n",
      "AO(2)               \t0.926 +- 0.041\t1.308 +- 0.090\t0.188 +- 0.005\n",
      "AO(3)               \t0.926 +- 0.041\t1.308 +- 0.090\t0.292 +- 0.006\n",
      "--- condition 4; m = 50, n = 20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method              \tcoverage\tlogbias\t\truntime\n",
      "wald                \t0.998 +- 0.006\t1.954 +- 0.190\t0.019 +- 0.002\n",
      "likelihood-profile  \t0.942 +- 0.039\t1.278 +- 0.183\t0.644 +- 0.011\n",
      "barrier             \t0.098 +- 0.039\t-inf +- nan\t0.069 +- 0.001\n",
      "AO(1)               \t0.938 +- 0.040\t1.254 +- 0.183\t0.040 +- 0.001\n",
      "AO(2)               \t0.942 +- 0.039\t1.278 +- 0.183\t0.221 +- 0.003\n",
      "AO(3)               \t0.942 +- 0.039\t1.278 +- 0.183\t0.352 +- 0.005\n",
      "--- condition 5; m = 100, n = 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:30<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method              \tcoverage\tlogbias\t\truntime\n",
      "wald                \t0.998 +- 0.004\t1.812 +- 0.130\t0.023 +- 0.005\n",
      "likelihood-profile  \t0.934 +- 0.028\t1.324 +- 0.126\t1.605 +- 0.063\n",
      "barrier             \t0.892 +- 0.029\t1.163 +- 0.131\t0.197 +- 0.019\n",
      "AO(1)               \t0.933 +- 0.027\t1.316 +- 0.126\t0.071 +- 0.009\n",
      "AO(2)               \t0.934 +- 0.028\t1.324 +- 0.126\t0.491 +- 0.015\n",
      "AO(3)               \t0.934 +- 0.028\t1.324 +- 0.126\t0.659 +- 0.025\n",
      "--- condition 6; m = 100, n = 20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:35<00:00,  3.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method              \tcoverage\tlogbias\t\truntime\n",
      "wald                \t0.999 +- 0.003\t2.024 +- 0.145\t0.048 +- 0.058\n",
      "likelihood-profile  \t0.937 +- 0.030\t1.306 +- 0.137\t1.872 +- 0.054\n",
      "barrier             \t0.059 +- 0.012\t-inf +- nan\t0.161 +- 0.008\n",
      "AO(1)               \t0.933 +- 0.031\t1.291 +- 0.136\t0.080 +- 0.011\n",
      "AO(2)               \t0.937 +- 0.030\t1.306 +- 0.137\t0.577 +- 0.015\n",
      "AO(3)               \t0.937 +- 0.030\t1.306 +- 0.137\t0.818 +- 0.039\n",
      "--- condition 7; m = 500, n = 10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:01<00:00, 30.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method              \tcoverage\tlogbias\t\truntime\n",
      "wald                \t0.998 +- 0.002\t1.837 +- 0.068\t0.145 +- 0.008\n",
      "likelihood-profile  \t0.940 +- 0.011\t1.318 +- 0.060\t16.868 +- 1.047\n",
      "barrier             \t0.898 +- 0.015\t1.170 +- 0.068\t1.924 +- 0.066\n",
      "AO(1)               \t0.939 +- 0.010\t1.316 +- 0.060\t0.410 +- 0.012\n",
      "AO(2)               \t0.940 +- 0.011\t1.318 +- 0.060\t4.605 +- 0.266\n",
      "AO(3)               \t0.940 +- 0.011\t1.318 +- 0.060\t6.205 +- 0.284\n",
      "--- condition 8; m = 500, n = 20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [03:20<05:02, 50.38s/it]<ipython-input-1-178cdb071133>:22: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.mean(np.log(ratios))\n",
      " 50%|█████     | 5/10 [04:10<04:10, 50.16s/it]<ipython-input-1-178cdb071133>:22: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.mean(np.log(ratios))\n",
      " 80%|████████  | 8/10 [06:42<01:40, 50.31s/it]<ipython-input-1-178cdb071133>:22: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.mean(np.log(ratios))\n",
      " 90%|█████████ | 9/10 [07:33<00:50, 50.58s/it]<ipython-input-1-178cdb071133>:22: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.mean(np.log(ratios))\n",
      "100%|██████████| 10/10 [08:23<00:00, 50.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method              \tcoverage\tlogbias\t\truntime\n",
      "wald                \t1.000 +- 0.001\t2.065 +- 0.044\t0.230 +- 0.017\n",
      "likelihood-profile  \t0.949 +- 0.008\t1.314 +- 0.044\t29.796 +- 0.735\n",
      "barrier             \t0.097 +- 0.016\t-inf +- nan\t1.857 +- 0.036\n",
      "AO(1)               \t0.948 +- 0.008\t1.310 +- 0.044\t0.479 +- 0.023\n",
      "AO(2)               \t0.949 +- 0.008\t1.314 +- 0.044\t8.010 +- 0.189\n",
      "AO(3)               \t0.949 +- 0.008\t1.314 +- 0.044\t9.983 +- 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/lib64/python3.10/site-packages/numpy/core/_methods.py:230: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n"
     ]
    }
   ],
   "source": [
    "# perform experiment in varying conditions\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import ability_bounds\n",
    "\n",
    "for i in range(len(experimental_conditions)):\n",
    "    m, n = experimental_conditions[i]\n",
    "    print('--- condition %d; m = %d, n = %d ---' % (i+1, m, n))\n",
    "\n",
    "    coverage = np.zeros((len(method_labels), R))\n",
    "    logbias  = np.zeros((len(method_labels), R))\n",
    "    runtimes = np.zeros((len(method_labels), R))\n",
    "\n",
    "    for r in tqdm(range(R)):\n",
    "        # sample new data set\n",
    "        theta, b, P, X = sample_data(m, n)\n",
    "        # iterate over all methods\n",
    "        for method in range(len(method_labels)):\n",
    "            # set up a fresh model\n",
    "            if method_labels[method] == 'wald':\n",
    "                model = ability_bounds.WaldBounds(regul, alpha)\n",
    "            elif method_labels[method] == 'likelihood-profile':\n",
    "                model = ability_bounds.LikelihoodProfile(regul, alpha)\n",
    "            elif method_labels[method] == 'barrier':\n",
    "                model = ability_bounds.BarrierBounds(regul, absolute_bound = absolute_bound)\n",
    "            elif method_labels[method].startswith('AO'):\n",
    "                num_iterations = int(method_labels[method][3])\n",
    "                model = ability_bounds.AOBounds(regul, absolute_bound = absolute_bound, num_iterations = num_iterations)\n",
    "            else:\n",
    "                raise ValueError('unknown method: %s' % method_labels[method])\n",
    "            # fit the model to the data\n",
    "            start = time.time()\n",
    "            model.fit(X)\n",
    "            runtimes[method, r] = time.time() - start\n",
    "            # evaluate the model\n",
    "            coverage[method, r] = eval_coverage(theta, model.theta_min_, model.theta_max_)\n",
    "            logbias[method, r]  = eval_logbias(theta, model.theta_, model.theta_min_, model.theta_max_)\n",
    "\n",
    "    # print current results\n",
    "    print('method              \\tcoverage\\tlogbias\\t\\truntime')\n",
    "    for method in range(len(method_labels)):\n",
    "        row = method_labels[method] + (20 - len(method_labels[method])) * ' '\n",
    "        for measure in [coverage, logbias, runtimes]:\n",
    "            row += '\\t%.3f +- %.3f' % (np.mean(measure[method, :]), np.std(measure[method, :]))\n",
    "        print(row)\n",
    "    # store current results\n",
    "    filename = 'results_%d_%d.csv' % (m, n)\n",
    "    datamat  = np.concatenate((coverage.T, logbias.T, runtimes.T), 1)\n",
    "    header   = []\n",
    "    for measure in ['coverage', 'logbias', 'runtime']:\n",
    "        for method_label in method_labels:\n",
    "            header.append('%s_%s' % (measure, method_label))\n",
    "    np.savetxt(filename, datamat, delimiter = '\\t', fmt = '%g', header = '\\t'.join(header), comments = '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
